{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# パーセプトロン基準を損失とする単層パーセプトロンの JAX 実装\n",
    "* Google Colab 上で動作を確認．\n",
    "* Iris は先頭の 50 個のデータが残りの 100 個から線形分離可能なデータセットです．\n",
    "* 問題のサイズが小さいのでJAX 使わずに NumPy で実装したほうが速く動作しました．JIT コンパイル時間抜きにしても２倍程度かかっています．GPU で動かすとさらに遅くなります（たぶんデータ転送オーバーヘッド）．\n",
    "* NumPy で実装した場合と訓練後の重みが若干違います．float 32 のせいかなと思いましたがそこまで影響はないようです．謎です．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install flax optax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "from functools import partial\n",
    "import jax.numpy as jnp\n",
    "from flax import linen as nn\n",
    "\n",
    "\n",
    "class PerceptronClassifier(nn.Module):\n",
    "    features: int = 1\n",
    "    use_bias: bool = False\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, X):\n",
    "        X = nn.Dense(\n",
    "            self.features, use_bias=self.use_bias, kernel_init=jax.nn.initializers.zeros\n",
    "        )(X)\n",
    "        return X\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def step(idx, state):\n",
    "    def loss_fn(params, X, y):\n",
    "        y_pred = state.apply_fn({\"params\": params}, X)\n",
    "        preloss = -y_pred * y\n",
    "        loss = (preloss + jnp.abs(preloss)) / 2.0\n",
    "        return loss[0]\n",
    "\n",
    "    X, y = X_train[idx], y_train[idx]\n",
    "    loss, grads = jax.value_and_grad(loss_fn)(state.params, X, y)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optax\n",
    "from flax.training.train_state import TrainState\n",
    "\n",
    "iris_dataset = load_iris()\n",
    "iris_dataset[\"target\"][0:50] = 1\n",
    "iris_dataset[\"target\"][50:] = -1\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris_dataset[\"data\"], iris_dataset[\"target\"], test_size=0.25\n",
    ")\n",
    "X_train, X_test, y_train, y_test = (\n",
    "    jax.device_put(X_train),\n",
    "    jax.device_put(X_test),\n",
    "    jax.device_put(y_train),\n",
    "    jax.device_put(y_test),\n",
    ")\n",
    "\n",
    "\n",
    "perceptron = PerceptronClassifier()\n",
    "params = perceptron.init(jax.random.PRNGKey(0), jnp.empty(4))[\"params\"]\n",
    "lr = 1.0\n",
    "tx = optax.scale(-2.0 * lr)\n",
    "state = TrainState.create(apply_fn=perceptron.apply, params=params, tx=tx)\n",
    "\n",
    "# training\n",
    "num_epochs = 3\n",
    "for epoch_idx in range(num_epochs):\n",
    "    state = jax.lax.fori_loop(0, X_train.shape[0], step, state)\n",
    "\n",
    "# test\n",
    "y_pred = jnp.ravel(\n",
    "    jnp.where(state.apply_fn({\"params\": state.params}, X_test) >= 0, 1, -1)\n",
    ")\n",
    "acc = jnp.mean(jnp.where(y_test - y_pred, 0, 1))\n",
    "print(\"Accuracy =\", acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c3107c4ef6221ac6857eaefaf4eb72303ad981098c912ff50e0bdc297ce3bbe0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
